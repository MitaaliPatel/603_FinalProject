{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "Pr4B0UGEwQU4",
        "outputId": "5913f847-df32-4998-8931-4b9608f32faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Unable to find py4j in /content/spark-3.3.2-bin-hadoop2.7/python, your SPARK_HOME may not be configured correctly",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mpy4j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lib\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"py4j-*.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e75a6878b5cc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Initialize findspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Start Spark session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mpy4j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lib\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"py4j-*.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             raise Exception(\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \"Unable to find py4j in {}, your SPARK_HOME may not be configured correctly\".format(\n\u001b[1;32m    163\u001b[0m                     \u001b[0mspark_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Unable to find py4j in /content/spark-3.3.2-bin-hadoop2.7/python, your SPARK_HOME may not be configured correctly"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install py4j\n",
        "\n",
        "# Set environment variables for Spark\n",
        "import os\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.3.2-bin-hadoop2.7'\n",
        "os.environ['PYTHONPATH'] = os.path.join(os.environ['SPARK_HOME'], 'python') + \":\" + os.path.join(os.environ['SPARK_HOME'], 'python', 'lib', 'py4j-*.zip')\n",
        "\n",
        "# Initialize findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Start Spark session\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"dataset\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovx6pu4_zTlm"
      },
      "outputs": [],
      "source": [
        "#reading the file\n",
        "df = spark.read.csv('/content/dataset.csv',header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwjsIgQRR_AG",
        "outputId": "42904f24-d381-4ff3-8d62-aa8810aee18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Header_Length: string (nullable = true)\n",
            " |-- Protocol Type: string (nullable = true)\n",
            " |-- Time_To_Live: string (nullable = true)\n",
            " |-- Rate: string (nullable = true)\n",
            " |-- fin_flag_number: string (nullable = true)\n",
            " |-- syn_flag_number: string (nullable = true)\n",
            " |-- rst_flag_number: string (nullable = true)\n",
            " |-- psh_flag_number: string (nullable = true)\n",
            " |-- ack_flag_number: string (nullable = true)\n",
            " |-- ece_flag_number: string (nullable = true)\n",
            " |-- cwr_flag_number: string (nullable = true)\n",
            " |-- ack_count: string (nullable = true)\n",
            " |-- syn_count: string (nullable = true)\n",
            " |-- fin_count: string (nullable = true)\n",
            " |-- rst_count: string (nullable = true)\n",
            " |-- HTTP: string (nullable = true)\n",
            " |-- HTTPS: string (nullable = true)\n",
            " |-- DNS: string (nullable = true)\n",
            " |-- Telnet: string (nullable = true)\n",
            " |-- SMTP: string (nullable = true)\n",
            " |-- SSH: string (nullable = true)\n",
            " |-- IRC: string (nullable = true)\n",
            " |-- TCP: string (nullable = true)\n",
            " |-- UDP: string (nullable = true)\n",
            " |-- DHCP: string (nullable = true)\n",
            " |-- ARP: string (nullable = true)\n",
            " |-- ICMP: string (nullable = true)\n",
            " |-- IGMP: string (nullable = true)\n",
            " |-- IPv: string (nullable = true)\n",
            " |-- LLC: string (nullable = true)\n",
            " |-- Tot sum: string (nullable = true)\n",
            " |-- Min: string (nullable = true)\n",
            " |-- Max: string (nullable = true)\n",
            " |-- AVG: string (nullable = true)\n",
            " |-- Std: string (nullable = true)\n",
            " |-- Tot size: string (nullable = true)\n",
            " |-- IAT: string (nullable = true)\n",
            " |-- Number: string (nullable = true)\n",
            " |-- Variance: string (nullable = true)\n",
            " |-- Label: string (nullable = true)\n",
            "\n",
            "+-------------+-------------+------------+------------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------+---------+---------+---------+----+-----+---+------+----+---+---+----+----+----+----+----+----+----+----+-------+---+----+-----+------------------+--------+--------------------+------+------------------+-----------------+\n",
            "|Header_Length|Protocol Type|Time_To_Live|              Rate|fin_flag_number|syn_flag_number|rst_flag_number|psh_flag_number|ack_flag_number|ece_flag_number|cwr_flag_number|ack_count|syn_count|fin_count|rst_count|HTTP|HTTPS|DNS|Telnet|SMTP|SSH|IRC| TCP| UDP|DHCP| ARP|ICMP|IGMP| IPv| LLC|Tot sum|Min| Max|  AVG|               Std|Tot size|                 IAT|Number|          Variance|            Label|\n",
            "+-------------+-------------+------------+------------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------+---------+---------+---------+----+-----+---+------+----+---+---+----+----+----+----+----+----+----+----+-------+---+----+-----+------------------+--------+--------------------+------+------------------+-----------------+\n",
            "|        19.92|            6|       63.36|25893.962217557724|            0.0|            0.0|            0.0|           0.99|           0.99|            0.0|            0.0|       99|        0|        0|        0| 0.0| 0.01|0.0|   0.0| 0.0|0.0|0.0|0.99| 0.0| 0.0|0.01| 0.0| 0.0|0.99|0.99|   6421| 60| 481|64.21| 42.09999999999997|   64.21|3.861904144287109E-5|   100|1772.4099999999978|DDOS-PSHACK_FLOOD|\n",
            "|          0.0|           47|        64.0| 3703.841330954946|            0.0|            0.0|            0.0|            0.0|            0.0|            0.0|            0.0|        0|        0|        0|        0| 0.0|  0.0|0.0|   0.0| 0.0|0.0|0.0| 0.0| 0.0| 0.0| 0.0|0.01| 0.0| 1.0| 1.0|  57320| 98| 578|573.2| 48.00000000000007|   573.2|   2.707815170288E-4|   100| 2304.000000000007|MIRAI-GREIP_FLOOD|\n",
            "|         7.92|           17|       65.91|19673.095684803004|            0.0|            0.0|            0.0|            0.0|            0.0|            0.0|            0.0|        0|        0|        0|        0| 0.0|  0.0|0.0|   0.0| 0.0|0.0|0.0| 0.0|0.99| 0.0| 0.0|0.01| 0.0| 1.0| 1.0|   6010| 60|  70| 60.1|1.0000000000000009|    60.1| 5.74493408203125E-5|   100|1.0000000000000018|    DOS-UDP_FLOOD|\n",
            "|         20.4|            6|       110.5| 261.6648262868622|            0.1|            0.0|            0.3|            0.2|            0.4|            0.0|            0.0|        4|        0|        1|        3| 0.0|  0.5|0.0|   0.0| 0.0|0.0|0.0| 0.7| 0.2| 0.0| 0.1| 0.0| 0.0| 0.9| 0.9|   2223| 54|1500|222.3| 451.5966858455304|   222.3|  0.0047659873962402|    10|203939.56666666668|     DNS_SPOOFING|\n",
            "|         0.32|            1|       63.96| 28944.19984818163|            0.0|            0.0|            0.0|            0.0|           0.01|            0.0|            0.0|        1|        0|        0|        0| 0.0| 0.01|0.0|   0.0| 0.0|0.0|0.0|0.01| 0.0| 0.0| 0.0|0.99| 0.0| 1.0| 1.0|   6006| 60|  66|60.06|0.5999999999999994|   60.06|3.455877304077148E-5|   100|0.3599999999999992|  DDOS-ICMP_FLOOD|\n",
            "+-------------+-------------+------------+------------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------+---------+---------+---------+----+-----+---+------+----+---+---+----+----+----+----+----+----+----+----+-------+---+----+-----+------------------+--------+--------------------+------+------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# View schema\n",
        "df.printSchema()\n",
        "\n",
        "# Show a few rows\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cyqizkeSCRV"
      },
      "outputs": [],
      "source": [
        "# Drop rows with any nulls\n",
        "df = df.dropna()\n",
        "\n",
        "# Drop duplicates\n",
        "df = df.dropDuplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JiUffLLSGC-"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Encode the target column\n",
        "label_indexer = StringIndexer(inputCol=\"Label\", outputCol=\"label_index\")\n",
        "df = label_indexer.fit(df).transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgFRfi2VSI7F"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Exclude label columns from conversion\n",
        "columns_to_convert = [c for c in df.columns if c not in ['Label', 'label_index']]\n",
        "\n",
        "# Cast all other columns to double\n",
        "for col_name in columns_to_convert:\n",
        "    df = df.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
        "\n",
        "# Exclude Label and label_index from features\n",
        "feature_cols = [col for col in df.columns if col not in [\"Label\", \"label_index\"]]\n",
        "\n",
        "# Assemble all features into one vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_unscaled\")\n",
        "df = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2rhXFGWSK-B"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\", withMean=True, withStd=True)\n",
        "scaler_model = scaler.fit(df)\n",
        "df = scaler_model.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_QWSSF5SNVM"
      },
      "outputs": [],
      "source": [
        "# Sample down to 10% to avoid memory issues\n",
        "sampled_df = df.select(\"features\", \"label_index\").sample(fraction=0.1, seed=42).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiL9-9m0SPDR"
      },
      "outputs": [],
      "source": [
        "# Convert Spark Vectors to NumPy arrays\n",
        "X = sampled_df['features'].apply(lambda x: x.toArray()).tolist()\n",
        "y = sampled_df['label_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyakFRPcSRaG",
        "outputId": "562265ab-a671-4b73-e084-d805a9327230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8425870101397643\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      6651\n",
            "         1.0       0.78      0.94      0.85      5963\n",
            "         2.0       1.00      1.00      1.00      4803\n",
            "         3.0       0.66      0.59      0.62      4742\n",
            "         4.0       0.71      0.89      0.79      4570\n",
            "         5.0       1.00      1.00      1.00      4503\n",
            "         6.0       0.88      0.63      0.74      4326\n",
            "         7.0       0.53      0.77      0.62      3995\n",
            "         8.0       0.76      0.49      0.59      3241\n",
            "         9.0       0.86      0.42      0.57      2685\n",
            "        10.0       0.97      1.00      0.98      1676\n",
            "        11.0       1.00      1.00      1.00      1505\n",
            "        12.0       1.00      1.00      1.00      1303\n",
            "        13.0       1.00      1.00      1.00      1139\n",
            "        14.0       1.00      1.00      1.00       669\n",
            "        15.0       0.99      0.96      0.98       571\n",
            "        16.0       0.97      0.97      0.97       474\n",
            "        17.0       1.00      1.00      1.00       420\n",
            "        18.0       1.00      1.00      1.00       427\n",
            "        19.0       1.00      0.97      0.98       304\n",
            "        20.0       0.99      0.99      0.99       207\n",
            "        21.0       0.96      0.90      0.93       148\n",
            "        22.0       0.98      0.94      0.96       140\n",
            "        23.0       1.00      1.00      1.00       127\n",
            "        24.0       1.00      1.00      1.00        39\n",
            "        25.0       1.00      1.00      1.00        45\n",
            "        26.0       1.00      1.00      1.00        23\n",
            "        27.0       1.00      0.89      0.94         9\n",
            "        28.0       1.00      1.00      1.00         4\n",
            "        29.0       1.00      1.00      1.00        10\n",
            "        30.0       1.00      1.00      1.00         4\n",
            "        31.0       1.00      1.00      1.00         6\n",
            "        32.0       1.00      1.00      1.00         2\n",
            "        33.0       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.84     54735\n",
            "   macro avg       0.94      0.92      0.93     54735\n",
            "weighted avg       0.86      0.84      0.84     54735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X)\n",
        "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}